# ğŸ‘• Team 22471A05 â€” Smart Apparel Narrator

A deep learningâ€“based system for **automatic caption generation of apparel images and videos** using **ConvNeXt-Large + LSTM architectures**.  
The project focuses on building a **robust, scalable, and deployment-ready fashion captioning pipeline** for e-commerce automation, accessibility support, and intelligent retail analytics.

---

# ğŸ‘¥ Team Info

### 22471A05A0 â€” Kanumuri Narendra
ğŸ”— LinkedIn: https://www.linkedin.com/in/narendra-kanumuri-6b4649276/  
**Work Done:** Designed the overall system architecture and implemented the ConvNeXtâ€“LSTM captioning pipeline. Developed image/video preprocessing, feature extraction, caption generation, and end-to-end model training.

---

### 22471A05B1 â€” Nallamekala Vignesh
ğŸ”— LinkedIn: https://www.linkedin.com/in/nallamekala-vignesh-9b992a361/  
**Work Done:** Performed dataset collection, cleaning, and preprocessing. Handled caption text processing, tokenization, padding, and conducted model evaluation using BLEU metrics and performance analysis.

---

### 22471A05B8 â€” Peddipaka Udaykiran
ğŸ”— LinkedIn: https://www.linkedin.com/in/uday-kiran-65bb88282/  
**Work Done:** Implemented video frame extraction using OpenCV, integrated feature extraction and inference pipeline, optimized training workflow, and supported deployment and visualization modules.

---

# ğŸ“Œ Abstract

This paper presents a deep learning-based framework named **Smart Apparel Narrator**, designed to automatically generate meaningful captions for fashion apparel in both images and videos. The system integrates a **ConvNeXt-Large encoder** for extracting detailed apparel features and an **LSTM decoder** for coherent caption generation.

For video sequences, the model applies **frame-level feature alignment** to capture dynamic apparel movements and maintain temporal consistency.

A filtered dataset containing **1,000+ annotated apparel images and clips across 26 fashion categories** was used for experimentation. The proposed method achieved strong balanced BLEU scores:

- BLEU-1: 0.946  
- BLEU-2: 0.932  
- BLEU-3: 0.924  
- BLEU-4: 0.917  

The framework supports:
- Automated e-commerce tagging  
- Assistive narration for visually impaired users  
- Fashion video analysis  
- Digital catalog management  

---

# ğŸ“„ Paper Reference (Inspiration)

ğŸ‘‰ **Image and Video Captioning for Apparels Using Deep Learning**  
Authors: Govind Agarwal, Kritika Jindal, Abishi Chowdhury, Vishal K. Singh, Amrit Pal  
https://ieeexplore.ieee.org/document/10636169

---

# ğŸš€ Our Improvements Over Existing Paper

### âŒ Removes frame-independent captioning
Generates context-aware captions instead of independent frame predictions.

### ğŸ“¦ Larger & cleaner dataset
Uses 1000+ curated images vs 863 base images â†’ better generalization.

### ğŸ”„ Frame-level feature alignment
Maintains temporal consistency and reduces caption flickering.

### ğŸ§  ConvNeXt-Large encoder
Captures fine-grained fashion details (texture, fabric, pattern, color).

### âœï¸ Improved linguistic fluency
Cleaner captions with better grammar and longer meaningful sentences.

### ğŸ“Š Balanced BLEU evaluation
0.946 / 0.932 / 0.924 / 0.917  
Ensures sentence-level coherence instead of unigram-only accuracy.

---

# ğŸ§© About the Project

This project implements a **deep learningâ€“based apparel captioning system** capable of automatically generating **natural language descriptions for clothing images and videos**.

### Applications
- E-commerce automation  
- Accessibility support  
- Fashion video narration  
- Smart retail analytics  

---

# ğŸ” Workflow

Input Image / Video  
â†’ Preprocessing  
â†’ ConvNeXt (Feature Extraction)  
â†’ LSTM (Caption Generation)  
â†’ Output Caption  

---

# ğŸ“Š Dataset Used

ğŸ‘‰ **Fashion Product Images Dataset (Kaggle)**  
https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset  

### Dataset Details
- ~44,000+ real-world apparel images  
- Multiple fashion categories  
- Rich metadata (gender, type, color, usage)  
- Suitable for captioning and classification tasks  

---

# ğŸ§° Dependencies Used

- ğŸ Python  
- ğŸ‘ï¸ OpenCV  
- ğŸ”¥ TensorFlow / Keras  
- ğŸ§  ConvNeXt-Large  
- ğŸ” LSTM  
- ğŸ“Š NumPy  
- ğŸ“ Pandas  
- ğŸ“ Tokenizer  
- ğŸ“‰ NLTK (BLEU)  
- ğŸ¨ Matplotlib  
- ğŸ’» Google Colab / Jupyter  

---

# ğŸ” EDA & Preprocessing

- Images converted to RGB format  
- Resized to 299Ã—299 / 512Ã—512  
- Corrupted/duplicate images removed  
- Dataset balance checked  
- Captions cleaned & tokenized  
- Padding applied  
- ConvNeXt feature extraction  
- Video frames processed individually  

---

# ğŸ§ª Model Training Info

- ConvNeXt generates feature embeddings  
- LSTM performs sequential caption generation  
- Cross-Entropy loss  
- Adam optimizer  
- Teacher forcing  
- 30 training epochs  
- BLEU-1 to BLEU-4 evaluation  

---

# ğŸ§¾ Model Testing / Evaluation

### Metrics Used
- BLEU-1  
- BLEU-2  
- BLEU-3  
- BLEU-4  

### Compared With
- CNNâ€“LSTM baseline  
- Attention-based models  
- Transformer models  

---

# ğŸ† Results

### Apparel Captioning
- BLEU-1: 0.946  
- BLEU-2: 0.932  
- BLEU-3: 0.924  
- BLEU-4: 0.917  

### Highlights
- Smooth video narration  
- Reduced caption flickering  
- ~150 ms/frame inference  
- Human-like descriptions  
- Suitable for real-time deployment  

---

# âš ï¸ Limitations & Future Work

### Limitations
- High GPU requirements  
- Slight latency for long videos  
- Performance may drop in complex scenes  

### Future Enhancements
- Real-time optimization  
- Larger datasets  
- Transformer/attention models  
- Web/mobile deployment  
- Multilingual captions  
- Text-to-speech integration  

---

# ğŸŒ Deployment Info

- Python backend  
- ConvNeXt + LSTM inference  
- CUDA GPU acceleration  
- OpenCV video processing  
- Flask / FastAPI deployment  
- Batch image/video support  

---

# âœ¨ Project By
ğŸ‘¨â€ğŸ’» Narendra Kanumuri
ğŸ‘¨â€ğŸ’» Nallamekala Vignesh
ğŸ‘¨â€ğŸ’» Peddipaka Udaykiran
ğŸ“ Smart Apparel Narrator â€” Deep Learning-Based Apparel Captioning System
